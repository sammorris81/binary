\documentclass{beamer}
\usepackage{beamerthemesplit}
% \usepackage{pstricks}
\usepackage{graphicx}
\usepackage{mdwlist}
\usepackage{lineno, hyperref}

\usepackage{amssymb,latexsym,amsmath,amsthm,bbm}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{multirow}
\usepackage{verbatim}
\usepackage{alltt}
\usepackage{mycommands}

\usepackage{cmbright}
\renewcommand*\familydefault{\sfdefault}
\usepackage[T1]{fontenc}


\definecolor{wp-red}{RGB}{204,0,0}
\definecolor{wp-gray}{RGB}{51,51,51}
\definecolor{reynolds-red}{RGB}{153,0,0}
\definecolor{pyroman-flame}{RGB}{209,81,34}
\definecolor{hunt-yellow}{RGB}{253,215,38}
\definecolor{genomic-green}{RGB}{125,140,31}
\definecolor{innovation-blue}{RGB}{66,126,147}
\definecolor{bio-indigo}{RGB}{65,86,161}

\setbeamercolor{structure}{fg=wp-red}
\setbeamercolor{title}{bg=white, fg=wp-red}  % changes color on title page
\setbeamerfont{title}{series=\bfseries, size=\huge}
\setbeamerfont{author}{series=\bfseries, size=\large}
\setbeamerfont{institute}{series=\mdseries, size=\large}

\setbeamercolor{frametitle}{bg=wp-red, fg=white}  % changes color at top of frame
\setbeamerfont{frametitle}{series=\bfseries}
\setbeamercolor{title in head/foot}{fg=white, bg=wp-red}  % changes color for title in footer
\setbeamerfont{title in head/foot}{series=\bfseries}
\setbeamercolor{author in head/foot}{fg=white,bg=wp-gray}  % changes color for author in footer
\setbeamerfont{author in head/foot}{series=\bfseries}


\title[Rare Binary Regression] % (optional, use only with long paper titles)
{
  Rare Binary Regression
}
\author[S. Morris and B. Reich]{Samuel Morris (NC State) and Brian Reich (NC State)}
\institute[NCSU]{}
\date{JSM 2015, Seattle}

\begin{document}

\begin{frame}\frametitle{\ }
\begin{center}
	\maketitle
\end{center}
\end{frame}

\begin{frame}{Motivation}
% data is 0 and 1, you want to model P(Y = 1)
\end{frame}

\begin{frame}{Binary regression}
% logit, probit, cloglog
\end{frame}

\begin{frame}{Generalized extreme value}
% cloglog is a special case of gev, Wang and Dey
\begin{itemize} \setlength{\itemsep}{1em}
  \item Link function is defined as
  \begin{align*}
    G(z_i) = 1 - \exp(-z_i)
  \end{align*}
  where
  \begin{align*}
    z_i = \left\{ \begin{array}{ll}
      (1 - \xi \bX_i \bbeta)^{1 / \xi} & \xi \neq 0 \\[0.5em]
      \exp(-\bX_i \bbeta) & \xi = 0
      \end{array} \right.
  \end{align*}
  is standardized to give unit Fr\'{e}chet distribution.
  \item Note: The cloglog link is a special case when $\xi = 0$
\end{itemize}
\end{frame}

\begin{frame}{Spatial setting: Logit and probit}
% what if observations aren't independent
\end{frame}

\begin{frame}{Spatial setting: GEV}
% when we assume the latent variable comes from a GEV, we should use a
% max-stable process
\end{frame}

\begin{frame}{Max-stable processes}
% challenging to work with, but there is a nice hierarchical representation
\end{frame}


\begin{frame}{Random effects representation}
% to help with large datasets, we use a random effects representation
% get dimension reduction with a grid of knots
\begin{itemize}
  \item Problem: $n$ is very large, and computationally challenging to work with
  \item Consider a set of $L << n$ knots $\bv_1, \ldots, \bv_L$
  \item At each knot, there is a random effect
  \begin{itemize}
    \item Logit and probit methods use Gaussian random effects
    \item GEV method uses Positive stable random effects
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Random effects representation}
  \begin{itemize}
    \item Logit and probit use kriging
    \begin{align*}
      z_i = \bX_i \bbeta + \theta_i
    \end{align*}
    \item The random effect impacts the marginal distribution for the GEV
    \begin{align*}
      \theta_i = \left[\sum_{l = 1}^L A_l w_l(\bs_i)^{1 / \alpha}\right]^{\alpha}
    \end{align*}

  \end{itemize}
\end{frame}

\begin{frame}{Method}
  \begin{itemize}
    \item Two-main steps for model fitting
    \item First, fit a pairwise composite likelihood
    \begin{itemize}
      \item Pairwise composite likelihood estimates used for initial values in MCMC
    \end{itemize}
    \item Then, fit a hierarchical random effects model using MCMC
  \end{itemize}
\end{frame}

\begin{frame}{Pairwise composite likelihood}
  \begin{itemize}
    \item We use a censored pairwise composite likelihood
    \begin{itemize}
      \item Marginalizes out random effects
    \end{itemize}
    \item Common in extremes
    \begin{itemize}
      \item Bivariate distributions are computationally tractible
      \item Only latent values where $Y = 1$ inform likelihood
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{MCMC}
  \begin{itemize}
    \item $Y | \ldots \ind \text{Bernoulli}(\pi_i)$
    \item $\pi_i = 1 - \exp\left\{ \sum_{l = 1}^L A_l \left[\frac{ w_l (\bs_i) }{z_i} \right] \right\}$
    \item $z_i = \left\{ \begin{array}{ll}
      (1 - \xi \bX_i \bbeta)^{1 / \xi} & \xi \neq 0 \\
      \exp(-\bX_i \bbeta) & \xi = 0
      \end{array} \right.$
    \item $A_l \iid \text{PS}(\alpha)$
    \item $w_l(\bs_i)$ is a scaled Gaussian kernel
  \end{itemize}
\end{frame}

\begin{frame}{Questions}
  \begin{itemize} \setlength{\itemsep}{0.5em}
    \item Questions?
    \item Thank you for your attention.
  \end{itemize}
\end{frame}

\begin{frame}{References}

\end{frame}

\end{document}