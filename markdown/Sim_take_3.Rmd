---
title: "Small Scale Sim"
author: "Morris, S."
date: "July 1, 2015"
output: pdf_document
---
```{r initial-setup, cache=TRUE, echo=FALSE, include = FALSE}
library(fields)
library(evd)
library(spBayes)
library(fields)
library(SpatialTools)
# library(microbenchmark)
library(mvtnorm)
library(Rcpp)
library(numDeriv)
Sys.setenv("PKG_CXXFLAGS"="-fopenmp")
Sys.setenv("PKG_LIBS"="-fopenmp")
sourceCpp(file = "../code/R/pairwise.cpp")

source("../code/R/auxfunctions.R", chdir = TRUE)
source("../code/R/updateModel.R")
source("../code/R/mcmc.R")
source("../code/R/probit.R", chdir=T)
```

# Small-scale simulation results

## Data settings

I generated data at 2000 sites using the following settings:

* $\alpha = 0.3$
* $\rho = 0.1$
* $\xi = 0$

This is 1500 sites for training, and 500 sites for cross validation.
The MCMC ran for 45000 iterations with 35000 burnin, and convergence isn't great, but it's more stable than before.

## Methods

There were 5 methods used to fit the datasets.

>  1a: Fix $\alpha$ and $\rho$ in the MCMC to be the estimates from the pairwise composite likelihood. Only fit $\beta$ and random effects in the MCMC.

> 1b: Fix $alpha$ in the MCMC to be the estimate from the pairwise composite likelihood, and fix $rho$ in the MCMC to be the knot spacing. Only fit $\beta$ and random effects in the MCMC.

> 1c: Fit $\alpha$, $\rho$, $beta$, and random effect in the MCMC.

> 2: Logit

> 3: Probit

Methods 1a, 1b, and 1c are all variations on rare binary.
Method 1a uses the pairwise composite likelihood to estimate $\alpha$ and $\rho$.
Method 1b uses the pairwise composite likelihood to estimate $\alpha$ with $\rho$ taken as the knot spacing.
Both 1a and 1b take $\beta$ to be the estimate for $\beta$ marginally for the sites when estimating $\alpha$ and $\rho$.

\newpage

## Results 

Here are the results for 10 datasets:

```{r compile-results, cache=TRUE, echo=FALSE, include = FALSE}
bs <- matrix(NA, 5, 10)
for (i in 1:10) {
  file <- paste("../code/R/pairwise-sim-", i, ".RData", sep = "")
  print(paste("start: set", i))
  load(file)
  bs[1, i] <- BrierScore(post.prob.gev.9, y.i.p)
  bs[2, i] <- BrierScore(post.prob.gev.10, y.i.p)
  if (i != 6) {
    bs[3, i] <- BrierScore(post.prob.gev, y.i.p)
  }
  bs[4, i] <- BrierScore(post.prob.log, y.i.p)
  bs[5, i] <- BrierScore(post.prob.pro, y.i.p)
}
```

\scriptsize
```{r simresults, echo=FALSE}
library(pander)
panderOptions("digits", 4)
rownames(bs) <- c("1a", "1b", "1c", "2", "3")
bs <- cbind(bs, rowMeans(bs, na.rm = TRUE))
colnames(bs) <- c(1:10, "Mean")
set.caption("Simulation results (x 100) for 10 datasets")
pander(t(bs) * 100)
```

\normalsize
So, some combination of 1b and 1c tend to help the performance of our rare binary method the most.
I also encountered a little bit of problem with dataset 6 when trying to fit all the parameters in the MCMC.
When I didn't fix $\alpha$ and $\rho$, as the MCMC was getting started, eventually the random effects would stop moving in the MCMC.
I don't know why they stopped.